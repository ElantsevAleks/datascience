{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **18 Чтение и запись данных. Часть 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Курс ведёт **Александр Джумурат** Data Scientist в ivi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **18.1** *JSON*\n",
    "\n",
    "JSON (англ. JavaScript Object Notation) — текстовый формат обмена данными, основанный на JavaScript. \n",
    "\n",
    "JSON представляет собой последовательность пар ключ-значение, ограниченных фигруными скобками, например: \n",
    "<pre>\n",
    "{\"firstName\": \"Ivan\", \"lastName\": \"Ivanov\", \"age\": 30}\n",
    "</pre>\n",
    "\n",
    "достоинства JSON\n",
    "* легко читается людьми\n",
    "* занимает меньше места в текстовом виде, чем аналогичный объект в формате XML (т.к. нету таких сущностей как тэги и нет необходимости писать открывающий/закрывающий тэг)\n",
    "* является \"родным\" форматом для Javascript, Python, MongoDB и других систем\n",
    "\n",
    "В силу этих особенностей, этот формат стал стандартом для передачи текстовой информации в сети интернет.\n",
    "\n",
    "В стандартный набор библиотек Python входит модуль `json`, кооторый используется для преобразования объектов (например, словарей) в текстовый JSON формат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Объект <class 'dict'> : \n",
      "{'firstName': 'Ivan', 'lastName': 'Ivanov', 'age': 30}\n"
     ]
    }
   ],
   "source": [
    "user = {\n",
    "    \"firstName\": \"Ivan\",\n",
    "    \"lastName\": \"Ivanov\", \n",
    "    \"age\": 30\n",
    "}\n",
    "\n",
    "print(\"Объект {} : \\n{}\".format(type(user), user))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем объект словаря в текстовый JSON формат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Объект <class 'str'> : {\"firstName\": \"Ivan\", \"lastName\": \"Ivanov\", \"age\": 30}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "user_json = json.dumps(user)\n",
    "print(\"Объект {} : {}\".format(type(user_json), user_json))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Готово! Мы молучили объект типа `str` который можно, например, передать по сети в другое приложение.\n",
    "\n",
    "Обратное преобразование `str->dict` выполняется с помощью той же библиотеки JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Объект <class 'dict'> : {'firstName': 'Ivan', 'lastName': 'Ivanov', 'age': 30}\n"
     ]
    }
   ],
   "source": [
    "user_dict = json.loads(user_json)\n",
    "print(\"Объект {} : {}\".format(type(user_dict), user_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **18.2** *Pickle - сериализация объектов*\n",
    "\n",
    "pickle (от англ. \"маринованные огурчики\") - это бинарный формат данных для хранение объектов Python. Вы можете запаковать объекты на одной машине и распаковать на другой - главное, чтобы версия питона при чтении была не ниже версии питона при записи. Pickle может сохранять простые объекты python - например, объекты numpy или словари. При дампе объектов из нестандартных библиотек (вроде sklearn) нужно гарантировать, что при распаковке объектов будут доступны те же самые библиотеки, иначе pickle может не справится."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_dict  -> {'foo': 'bar'}\n",
      "Неудача, словарь не найден\n",
      "temp_dict  -> {'foo': 'bar'}\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "\n",
    "# создаём объект python\n",
    "temp_dict = {'foo': 'bar'}\n",
    "\n",
    "print(\"temp_dict  -> {}\".format(temp_dict))\n",
    "\n",
    "# сохраняем объект в pickle\n",
    "with open('./data/dict.pkl', 'wb') as f:\n",
    "    pickle.dump(temp_dict, f)\n",
    "# удаляем словарь\n",
    "del temp_dict\n",
    "\n",
    "# проверяем, что удаление прошло успешно\n",
    "try:\n",
    "    print(\"temp_dict  -> {}\".format(temp_dict))\n",
    "except NameError:\n",
    "    print(\"Неудача, словарь не найден\")\n",
    "\n",
    "# загружаем сохраненный объект из pkl\n",
    "with open('./data/dict.pkl', 'rb') as f:\n",
    "    temp_dict = pickle.load(f)\n",
    "    \n",
    "print(\"temp_dict  -> {}\".format(temp_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В отличие от всех предыдущих форматов данных, которые являются текстовыми, pickle позволяет сохранять объекты python'a и загружать их непосредственно в память python'овского процессора без допольнительных преобразований из текстового вида."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **18.3** *Работа с данными формата HDF5*\n",
    "\n",
    "HDF5 (Hierarchical Data Format, HDF (Иерархический формат данных)) - бинарный формат, который позволяет эффективно хранить большие объемы данных. Реализация в Python имеет хорошую интеграцию с библиотекой векторных вычислений numpy. \n",
    "\n",
    "Основые преимущества формата:\n",
    "\n",
    "* хранение сложных иерархических структур\n",
    "* быстрый доступ к изолированным частям данных без загрузки в память (чтение с диска)\n",
    "\n",
    "Реализация в python называется [h5py](https://www.h5py.org/). Это довольно низкоуровневая библиотека, поэтому рекомендую дополнительно изучить удобную в использовании [PyTables](https://www.pytables.org/), которая является оберткой над h5py. Кроме того, данные в hdf позволяет сохранять библиотека для работы с табличными данными [pandas](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_hdf.html)\n",
    "\n",
    "HDF спроектирован для эффективного хранения многомерных массивов. \n",
    "\n",
    "Для примера работы получим три массива numpy и сохраним их в формат HDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерности матриц U=(10000, 40), s=(40,), V=(40, 1000)\n",
      "Типы матриц U=<class 'numpy.ndarray'>, s=<class 'numpy.ndarray'>, V=<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import random\n",
    "import numpy as np\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "# формируем массив случайных чисел\n",
    "user_item_matrix = random(10000, 1000, density=0.01, format='coo', dtype=np.int32, random_state=42)\n",
    "user_item_matrix = user_item_matrix.asfptype()\n",
    "# разделяем массив на три части, каждую из которых будем хранить отдельно\n",
    "U, s, V = svds(user_item_matrix, k=40)\n",
    "\n",
    "print(\"Размерности матриц U={}, s={}, V={}\".format(U.shape, s.shape, V.shape))\n",
    "print(\"Типы матриц U={}, s={}, V={}\".format(type(U), type(s), type(V)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логической единицей хранения в hdf является dataset. Работа с датасетом не отличается от работы с текстовыми файлами, которые мы изучили ранее в курсе: мы создаём менеджер контекста **h5py.File** и загружаем датасет внутри контекста. За пределами менеджера контекста датасет доступен не будет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Создали датасет в менеджере контекста: <HDF5 dataset \"default\": shape (40,), type \"<f8\">\n",
      "Датасет вне менеджера контекста недоступен: <Closed HDF5 dataset>\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "with h5py.File('./data/s_matrix.hdf5', 'w') as f:\n",
    "    h5py_dset = f.create_dataset(\"default\", data=s)\n",
    "    print('Создали датасет в менеджере контекста: {}'.format(h5py_dset))\n",
    "\n",
    "print('Датасет вне менеджера контекста недоступен: {}'.format(h5py_dset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Киллерфича hdf5 - сохранение датасет сложной структуры. Ближаший аналог - модуль pickle умеет сохранять только питоновские объекты, в то время как h5py способен хранить \"разветвлённые\" иерархические данные.\n",
    "\n",
    "Сохраним три отдельных numpy.array в едином датасете:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уровень группы:\t\tItemsViewHDF5(<HDF5 group \"/source_data\" (2 members)>)\n",
      "Уровень подгруппы\tItemsViewHDF5(<HDF5 group \"/source_data/model_data\" (3 members)>)\n",
      "\n",
      "Имена элементов в подгруппе:\n",
      "\n",
      "/source_data/model_data/eigen_values\n",
      "/source_data/model_data/item_factors\n",
      "/source_data/model_data/user_factors\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('./data/complex_dataset.hdf5', 'w') as f:\n",
    "    # создаём группу raw\n",
    "    raw = f.create_group('source_data')\n",
    "    raw.create_dataset('./data/complex_dataset.hdf5', data=np.random.random(1000))\n",
    "    # создаём подгруппу processed\n",
    "    processed = raw.create_group('model_data')\n",
    "    # в подгруппе proceessed группы raw создаём датасет\n",
    "    processed.create_dataset('user_factors', data=U, dtype=np.float32, compression=\"gzip\")\n",
    "    processed.create_dataset('eigen_values', data=s, dtype=np.float32, compression=\"gzip\")\n",
    "    processed.create_dataset('item_factors', data=V, dtype=np.float32, compression=\"gzip\")\n",
    "    \n",
    "    print(\"Уровень группы:\\t\\t{}\".format(raw.items()))\n",
    "    print(\"Уровень подгруппы\\t{}\".format(processed.items()))\n",
    "    # формируем список элементов, которые есть в подгруппе\n",
    "    print(\"\\nИмена элементов в подгруппе:\\n\")\n",
    "    group_names = [i.name for i in f['source_data/model_data'].values()]\n",
    "    for name in group_names:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1664366    9/7/2020    3:50:40 AM  D:\\Љгабл\\Skillbox\\Data Science\\18. —вҐ­ЁҐ Ё § ЇЁбм ¤ ­­ле з.2\\data\\complex_dataset.hdf5\n",
      "      2368    9/7/2020    3:50:40 AM  D:\\Љгабл\\Skillbox\\Data Science\\18. —вҐ­ЁҐ Ё § ЇЁбм ¤ ­­ле з.2\\data\\s_matrix.hdf5\n"
     ]
    }
   ],
   "source": [
    "# для Windows\n",
    "!where /R data /T *.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 adzhumurat adzhumurat 1,6M апр 14 19:20 complex_dataset.hdf5\n",
      "-rw-r--r-- 1 adzhumurat adzhumurat 2,4K апр 14 19:20 s_matrix.hdf5\n"
     ]
    }
   ],
   "source": [
    "# для Linux\n",
    "!ls -hla ./data | grep hdf5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже мы сохраням все результаты разложения в директорию `/data/`. Когда мы открываем датасет на чтение, он доступен для применения различных функций (вроде min, max), но при этом он теряет свойства numpy.ndarray. Чтобы перейти обратно к массиву можно сделать slice - мы итеративно пройдёмся по данным на диске и \"соберём\" их обратно в numpy.ndarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доступные ключи ['default']\n",
      "\n",
      "min=15967970843.644163, \n",
      "max=16869307715.289244, \n",
      "slice=[1.61010982e+10 1.61161420e+10 1.61308403e+10 1.61512488e+10\n",
      " 1.61722312e+10]\n",
      "\n",
      "Попытка воспользоваться функциями numpy...\n",
      "Не вышло =(\n",
      "Типизация датасетов: data=<Closed HDF5 dataset>, data_copy=<class 'numpy.ndarray'>\n",
      "\n",
      "Размерности матриц U=(10000, 40), s=(40,), V=(40, 1000)\n",
      "Типизация матриц U=<class 'numpy.ndarray'>, s=<class 'numpy.ndarray'>, V=<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('./data/s_matrix.hdf5', 'r') as f:\n",
    "    print(\"Доступные ключи %s\\n\" % list(f.keys()))\n",
    "    data = f['default']\n",
    "    print(\"min={}, \\nmax={}, \\nslice={}\\n\".format(min(data), max(data), data[10:15]))\n",
    "    print(\"Попытка воспользоваться функциями numpy...\")\n",
    "    try:\n",
    "        print(data.min())\n",
    "    except AttributeError:\n",
    "        print(\"Не вышло =(\")\n",
    "    data_copy = data[:]\n",
    "print(\"Типизация датасетов: data={}, data_copy={}\\n\".format(data, type(data_copy)))\n",
    "\n",
    "# Чтение иерархических датасетов\n",
    "with h5py.File('./data/complex_dataset.hdf5', 'r') as f:\n",
    "    U_hdf = f['source_data/model_data/user_factors'][:]\n",
    "    s_hdf = f['source_data/model_data/eigen_values'][:]\n",
    "    V_hdf = f['source_data/model_data/item_factors'][:]\n",
    "    \n",
    "print(\"Размерности матриц U={}, s={}, V={}\".format(U_hdf.shape, s_hdf.shape, V_hdf.shape))\n",
    "print(\"Типизация матриц U={}, s={}, V={}\".format(type(U_hdf), type(s_hdf), type(V_hdf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **18.4** *Работа с БД: SQLite3*\n",
    "\n",
    "sqlite3 - либа для работы с реляционными СУБД. Реляционные СУБД представляют собой таблицы, которые соединяются друг с другом с помощью ключей. Ключ - это поле, значение которого в одной таблице совпадает со значением в другой таблице."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Типизация connection <class 'sqlite3.Connection'>, типизация cursor <class 'sqlite3.Cursor'>\n",
      "\n",
      "Выполняем INSERT в базу...\n",
      "Выполнили INSERT, закрываем соединение\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import csv\n",
    "\n",
    "conn = sqlite3.connect('./data/example.db') # создаём подключение к БД из дампа\n",
    "c = conn.cursor() # специальный объект cursor, который служит для доступа к таблицам БД\n",
    "print(\"Типизация connection {}, типизация cursor {}\\n\".format(type(conn), type(c)))\n",
    "\n",
    "# Create table\n",
    "c.execute('''DROP TABLE IF EXISTS jira_task''') # удаляем таблицу, если она уже есть в БД чтобы не дублировать данные\n",
    "c.execute('''CREATE TABLE jira_task (code text, theme text, time_plan real, time_fact real)''') # создаём таблицу jira_task\n",
    "\n",
    "with open('./data/task.csv', 'r', encoding='utf8') as fin: # т.н. менеджер контекста, аналогично уроку про чтение из файлов в python \n",
    "    # csv.DictReader использует первую строку текстового файла как заголовки столбцов по умолчанию\n",
    "    dr = csv.reader(fin) # запятая - разделитель полей по умолчанию\n",
    "    next(dr, None)  # пропускаем заголовок\n",
    "    dataset = [(i[0], i[1], i[2], i[3]) for i in dr]\n",
    "\n",
    "print(\"Выполняем INSERT в базу...\")\n",
    "c.executemany(\"INSERT INTO jira_task VALUES (?, ?, ? ,?);\", dataset) # загрузка сформированного датасета в БД\n",
    "print(\"Выполнили INSERT, закрываем соединение\")\n",
    "conn.commit() # функция commit сохраняет состояние БД\n",
    "conn.close() # функция colse закрывает соединение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После того, как таблицы созданы, можно читать из них данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Открываем соединение с БД и читаем данные...\n",
      "\n",
      "('HYDRA-535', 'Пробрасывать пользовательское распределение paid_types в ехидну', 'echidna', 1.0)\n",
      "('HYDRA-534', 'Гибридный рекомендатель с multi-channel feedback', 'hydra', 3.0)\n",
      "('HYDRA-532', 'Джоба в дженкинсе для расчёта динамики РВП', 'hydramatrices', 2.0)\n",
      "('HYDRA-531', 'Интеграция Hydra с Gamora', 'hydramagrices', 4.0)\n",
      "('HYDRA-530', 'Тестируем интеграцию с Jira', 'hydra', 2.0)\n",
      "('HYDRA-527', 'Поправить функцию _get_ui_rec_matrix', 'hydra', 10.0)\n",
      "('HYDRA-524', 'Оптимизировать матрицу ItemFactors', 'hydra', 2.0)\n",
      "('HYDRA-523', 'Сортировка ЦПБ', 'hydra', 5.0)\n",
      "('HYDRA-520', 'Закостылить параметр top', 'hydra', 2.0)\n",
      "('HYDRA-519', \"Сделать 'stable' конфигом по умолчанию в Гидре\", 'hydra', 2.0)\n",
      "\n",
      "Типизация строки <class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Открываем соединение с БД и читаем данные...\\n\")\n",
    "conn = sqlite3.connect('./data/example.db')\n",
    "c = conn.cursor()\n",
    "some_row = None\n",
    "for row in c.execute('SELECT * FROM jira_task LIMIT 10;'): # читаем первые 10 строк из БД\n",
    "        print(row)\n",
    "        some_row = row\n",
    "conn.close()\n",
    "print(\"\\nТипизация строки %s\" % type(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **18.5** *Работа с БД: PostgreSQL*\n",
    "\n",
    "psycopg2 - библиотека для подключения к Postgres. Postgres - реляционная СУБД. Она содержит следующие сущности\n",
    "* database - база данных\n",
    "* table - таблица\n",
    "\n",
    "Таблицы могут соединяться друг с другом с помощью операции **join** - то есть зависят друг от друга, поэтому такой тип хранилищ данных называется *реляционным*\n",
    "\n",
    "Каждая таблица состоит из *кортежей* (или, по простому, строк). Данные из БД можно читать построчно.\n",
    "\n",
    "Чтобы читать таблицу из БД, нужно авторизоваться с импользованием логина и пароля."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "pg_connection = {\n",
    "    \"host\": \"dsstudents.skillbox.ru\",\n",
    "    \"port\": 5432,\n",
    "    \"dbname\": \"db_ds_students\",\n",
    "    \"user\": \"readonly\",\n",
    "    \"password\": \"6hajV34RTQfmxhS\"\n",
    "}\n",
    "conn = psycopg2.connect(**pg_connection)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним простейший запрос, который выведет все таблицы в базе *public*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Какие таблицы содержатся в Postgres: [('keywords',), ('links',), ('ratings',), ('exploratory',), ('course_purchases',), ('joi',)]\n"
     ]
    }
   ],
   "source": [
    "# запрос, который выведет все таблицы в базе public\n",
    "sql_str = \"SELECT table_name FROM information_schema.tables WHERE table_schema='public';\"\n",
    "\n",
    "cursor.execute(sql_str)\n",
    "tables_data = [a for a in cursor.fetchall()] # метод fetchall возвращает все строки, которые удалось прочитать из запроса\n",
    "conn.commit()\n",
    "\n",
    "print(\"Какие таблицы содержатся в Postgres: %s\" % tables_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Postrgres - мощный аналитический инструмент, которорый позволяет перенести сложные расчёты из python на уровень ниже - в СУБД, которая хранит данные. СУБД представляет собой мощное вычислительное средство. Воспользуемся этим средством и сформируем аналитический запрос: посчитаем среднюю оценку по фильмам, у которых более 10 оценок и выведем top-5 таких фильмов с самой максимальной оценкой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movieId: 632      avg_rating: 4.63636363636364\n",
      "movieId: 142115   avg_rating: 4.625\n",
      "movieId: 99764    avg_rating: 4.58333333333333\n",
      "movieId: 7096     avg_rating: 4.57142857142857\n",
      "movieId: 4046     avg_rating: 4.55555555555556\n",
      "movieId: 8724     avg_rating: 4.5\n",
      "movieId: 111778   avg_rating: 4.5\n",
      "movieId: 5169     avg_rating: 4.5\n",
      "movieId: 4405     avg_rating: 4.5\n",
      "movieId: 159817   avg_rating: 4.47826086956522\n",
      "\n",
      "Типизация строки <class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "pg_connection = {\n",
    "    \"host\": \"dsstudents.skillbox.ru\",\n",
    "    \"port\": 5432,\n",
    "    \"dbname\": \"db_ds_students\",\n",
    "    \"user\": \"readonly\",\n",
    "    \"password\": \"6hajV34RTQfmxhS\"\n",
    "}\n",
    "conn = psycopg2.connect(**pg_connection)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# запрос\n",
    "sql_str = \"\"\"\n",
    "    SELECT \n",
    "        movieId, AVG(rating) as avg_rating\n",
    "    FROM public.ratings \n",
    "    GROUP BY movieId\n",
    "    HAVING COUNT(RATING)>10\n",
    "    ORDER BY avg_rating DESC\n",
    "    LIMIT 10;\n",
    "\"\"\"\n",
    "cursor.execute(sql_str)\n",
    "\n",
    "\n",
    "for row in cursor:\n",
    "    print('movieId: %s %s avg_rating: %s' % (row[0], (7-len(str(row[0])))*' ', row[1]))\n",
    "conn.close()\n",
    "print(\"\\nТипизация строки %s\" % type(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **18.6** *Работа с БД из pandas*\n",
    "\n",
    "Если в вашей БД хранится небольшое количество данных, которое помещается в оперативную память, то к базам можно подключатьться с помощью pandas. Для этих целей идеально подойдёт функция [pandas.read_sql_query](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_sql_query.html)\n",
    "\n",
    "Прочитаем данные из sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>theme</th>\n",
       "      <th>time_plan</th>\n",
       "      <th>time_fact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HYDRA-535</td>\n",
       "      <td>Пробрасывать пользовательское распределение pa...</td>\n",
       "      <td>echidna</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HYDRA-534</td>\n",
       "      <td>Гибридный рекомендатель с multi-channel feedback</td>\n",
       "      <td>hydra</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HYDRA-532</td>\n",
       "      <td>Джоба в дженкинсе для расчёта динамики РВП</td>\n",
       "      <td>hydramatrices</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HYDRA-531</td>\n",
       "      <td>Интеграция Hydra с Gamora</td>\n",
       "      <td>hydramagrices</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HYDRA-530</td>\n",
       "      <td>Тестируем интеграцию с Jira</td>\n",
       "      <td>hydra</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        code                                              theme  \\\n",
       "0  HYDRA-535  Пробрасывать пользовательское распределение pa...   \n",
       "1  HYDRA-534   Гибридный рекомендатель с multi-channel feedback   \n",
       "2  HYDRA-532         Джоба в дженкинсе для расчёта динамики РВП   \n",
       "3  HYDRA-531                          Интеграция Hydra с Gamora   \n",
       "4  HYDRA-530                        Тестируем интеграцию с Jira   \n",
       "\n",
       "       time_plan  time_fact  \n",
       "0        echidna        1.0  \n",
       "1          hydra        3.0  \n",
       "2  hydramatrices        2.0  \n",
       "3  hydramagrices        4.0  \n",
       "4          hydra        2.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"./data/example.db\")\n",
    "df = pd.read_sql_query(\"select * from jira_task limit 5;\", conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаем данные из postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>movieid</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4982</td>\n",
       "      <td>3793</td>\n",
       "      <td>5.0</td>\n",
       "      <td>995933596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4982</td>\n",
       "      <td>3826</td>\n",
       "      <td>3.0</td>\n",
       "      <td>995933278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4982</td>\n",
       "      <td>3863</td>\n",
       "      <td>4.0</td>\n",
       "      <td>995933094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4982</td>\n",
       "      <td>3949</td>\n",
       "      <td>5.0</td>\n",
       "      <td>995933663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4982</td>\n",
       "      <td>3977</td>\n",
       "      <td>3.0</td>\n",
       "      <td>995933094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userid  movieid  rating  timestamp\n",
       "0    4982     3793     5.0  995933596\n",
       "1    4982     3826     3.0  995933278\n",
       "2    4982     3863     4.0  995933094\n",
       "3    4982     3949     5.0  995933663\n",
       "4    4982     3977     3.0  995933094"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "pg_connection = {\n",
    "    \"host\": \"dsstudents.skillbox.ru\",\n",
    "    \"port\": 5432,\n",
    "    \"dbname\": \"db_ds_students\",\n",
    "    \"user\": \"readonly\",\n",
    "    \"password\": \"6hajV34RTQfmxhS\"\n",
    "}\n",
    "conn = psycopg2.connect(**pg_connection)\n",
    "\n",
    "df = pd.read_sql_query(\"select * from public.ratings limit 5;\", conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **18.7-18.8** *Работа с БД: MongoDB. Часть 1*\n",
    "\n",
    "MongoDB - это т.н. **документоориентированная БД**, иногда их ещё называют бессхемными (schema-less).\n",
    "\n",
    "В противоположность реляционным БД, где есть таблицы со строками, MongoDB оперирует другими понятиями:\n",
    "* database - база данных, как в Postgres\n",
    "* collection - коллекция, аналог таблицы\n",
    "* document - документ, аналог строки в таблице\n",
    "\n",
    "В отличие от реляционных БД, где все строки в таблице имеют одинаковые поля, каждый документ в коллекции MongoDB потенциально может иметь свой уникальный набор полей.\n",
    "(Обычно так не делают. И большинство полей всё же пересекаются. Однако, в некоторых БД могут присутствовать поля, которых нет в других документах).\n",
    "\n",
    "Подключёние происходит с помощью библиотеки **pymongo**, для подключения к БД нужно авторизоваться. Попробуем подключиться к БД и вытащить список доступных коллекций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Коллекции, доступные в MongoDB: ['tags', 'users']\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "mongo_connection = {\n",
    "    \"host\": \"dsstudents.skillbox.ru\",\n",
    "    \"port\": 27017,\n",
    "    \"user\": \"students\",\n",
    "    \"password\": \"X63673t47Gl03Sq\",\n",
    "    \"authSource\": \"movies\"\n",
    "}\n",
    "\n",
    "mongo = MongoClient('mongodb://%s:%s@%s:%s/?authSource=%s' % (\n",
    "    mongo_connection['user'], mongo_connection['password'],\n",
    "    mongo_connection['host'], mongo_connection['port'], mongo_connection['authSource'])\n",
    ")\n",
    "db = mongo[\"movies\"]\n",
    "\n",
    "print(\"Коллекции, доступные в MongoDB: %s\" % db.list_collection_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MongroDB также является мощным вычислительным средством аналогично Postgre.\n",
    "\n",
    "Можно посчитать самую простую статистику - количество документов в коллекции с помощью функции *.count()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число документов в коллекции 158680\n"
     ]
    }
   ],
   "source": [
    "collection = db['tags']\n",
    "print(\"Число документов в коллекции %s\" % collection.estimated_document_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат выборки: объект типа cursor <pymongo.cursor.Cursor object at 0x0000029A89462C40>\n",
      "\n",
      "Сожержимое курсора:\n",
      "[{'_id': ObjectId('5c822402c0669da98bd5081e'), 'id': 931, 'name': 'jealousy'}, {'_id': ObjectId('5c822402c0669da98bd5081f'), 'id': 4290, 'name': 'toy'}, {'_id': ObjectId('5c822402c0669da98bd50820'), 'id': 5202, 'name': 'boy'}, {'_id': ObjectId('5c822402c0669da98bd50821'), 'id': 6054, 'name': 'friendship'}, {'_id': ObjectId('5c822402c0669da98bd50822'), 'id': 9713, 'name': 'friends'}]\n",
      "\n",
      "Поля элемента курсора ['_id', 'id', 'name']\n"
     ]
    }
   ],
   "source": [
    "mongo_cursor = collection.find().limit(5) # функция find - аналог оператора WHERE в SQL\n",
    "print(\"Результат выборки: объект типа cursor %s\\n\" % mongo_cursor)\n",
    "\n",
    "# пройдёмся по курсору и посмотрим, что внутри\n",
    "cursor_items = [item for item in mongo_cursor]\n",
    "print(\"Сожержимое курсора:\\n%s\\n\" % cursor_items)\n",
    "print(\"Поля элемента курсора %s\" % list(cursor_items[0].keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В метод *.find()* может принимать в том числе и аргументы. Например, т.н. *селектор*. *Селектор* - это словарь, который помогает оставить в выдачё только нужные поля. Селектор задаётся атрибутом *projection*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Содержимое курсора (оставляем только поле 'name'):\n",
      "[{'_id': ObjectId('5c822402c0669da98bd5081e'), 'name': 'jealousy'}, {'_id': ObjectId('5c822402c0669da98bd5081f'), 'name': 'toy'}, {'_id': ObjectId('5c822402c0669da98bd50820'), 'name': 'boy'}, {'_id': ObjectId('5c822402c0669da98bd50821'), 'name': 'friendship'}, {'_id': ObjectId('5c822402c0669da98bd50822'), 'name': 'friends'}]\n",
      "\n",
      "Сожержимое курсора (выключаем _id):\n",
      "[{'id': 931, 'name': 'jealousy'}, {'id': 4290, 'name': 'toy'}, {'id': 5202, 'name': 'boy'}, {'id': 6054, 'name': 'friendship'}, {'id': 9713, 'name': 'friends'}]\n",
      "\n",
      "Сожержимое курсора без лишних полей:\n",
      "[{'name': 'jealousy'}, {'name': 'toy'}, {'name': 'boy'}, {'name': 'friendship'}, {'name': 'friends'}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selector = {'name': True}\n",
    "mongo_cursor = collection.find(projection=selector).limit(5)\n",
    "cursor_items = [item for item in mongo_cursor]\n",
    "print(\"Содержимое курсора (оставляем только поле 'name'):\\n%s\\n\" % cursor_items)\n",
    "\n",
    "# Нам мешается поле \"_id\" - можем выключить его\n",
    "selector = {'_id': False}  \n",
    "mongo_cursor = collection.find(projection=selector).limit(5)\n",
    "cursor_items = [item for item in mongo_cursor]\n",
    "print(\"Сожержимое курсора (выключаем _id):\\n%s\\n\" % cursor_items)\n",
    "\n",
    "#  можем выключить  поле \"_id\" и включить \"name\"\n",
    "selector = {'_id': False, 'name': True}\n",
    "mongo_cursor = collection.find(projection=selector).limit(5)\n",
    "cursor_items = [item for item in mongo_cursor]\n",
    "print(\"Сожержимое курсора без лишних полей:\\n%s\\n\" % cursor_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Работа с БД: MongoDB. Часть 2*\n",
    "\n",
    "Фильтровать можно с помощью параметра *.filter()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сожержимое курсора (оставляем только 'name'=='toy'):\n",
      "[{'id': 4290, 'name': 'toy'}, {'id': 4290, 'name': 'toy'}, {'id': 4290, 'name': 'toy'}, {'id': 4290, 'name': 'toy'}, {'id': 4290, 'name': 'toy'}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selector = {'name': 'toy'}\n",
    "exclude_id = {'_id': False}\n",
    "mongo_cursor = collection.find(projection=exclude_id, filter={'name': 'toy'}).limit(5) # фильтр позволяет оставить только нужные нам тэги\n",
    "cursor_items = [item for item in mongo_cursor]\n",
    "print(\"Сожержимое курсора (оставляем только 'name'=='toy'):\\n%s\\n\" % cursor_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MongoDB позволяет также выполнять сложные агрегирующие запросы средствами СУБД"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': 'woman director', 'tag_count': 3115}, {'_id': 'independent film', 'tag_count': 1930}, {'_id': 'murder', 'tag_count': 1308}, {'_id': 'based on novel', 'tag_count': 835}, {'_id': 'musical', 'tag_count': 734}]\n"
     ]
    }
   ],
   "source": [
    "pipline = [\n",
    "    {\"$group\":            # этап группировки данных\n",
    "        {\"_id\": \"$name\",  # гурппируем по полю name\n",
    "         \"tag_count\":     # для каждого названия тэга\n",
    "            {\"$sum\": 1}   # мы печатаем сумму вхождений этого тэга в коллекцию\n",
    "         }\n",
    "     },\n",
    "    {\"$sort\":             # отсортируем все наши записи\n",
    "        {\"tag_count\": -1} # по полю tag_count в обратном порядке (по убыванию)\n",
    "     },\n",
    "    {\"$limit\": 5}         # передаём модификатор limit (из выдачи оставим только 5 элементов)\n",
    "]\n",
    "\n",
    "print([i for i in collection.aggregate(pipline)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы познакомились с нереляционным хранилищем данных *MongoDB*. *MongoDB* хранит в себе элементы, очень похожие на словари в Python. Поэтому формировать выдачу из словарей очень просто, и с помощью *MongoDB* можно строить сложные аналитические запросы, которые включают в себя аггрегацию данных и их сортировку.\n",
    "\n",
    "## *Итоги*\n",
    "\n",
    "В этом модуле мы познакомились с огромным количеством разных форматов данных:\n",
    "- с очень распространённым текстовым форматом JSON\n",
    "- с бинарными форматами данных, такими как pickle и более продвинутый формат для иерархического хранения данных - hdf5\n",
    "\n",
    "Кроме того, мы узнали, что данные можно хранить не только на локальном компьютере в файлах или бинарных файлах, но и с помощью баз данных. В частности, мы познакомились с такими БД как:\n",
    "- простая SQLite3\n",
    "- более продвинутая PostreSQL\n",
    "- нереляционная БД MongroDB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
